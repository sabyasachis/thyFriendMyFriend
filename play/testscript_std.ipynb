{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test script\n",
    "This is a standard test script which can be used to simply give a dataset as input(make sure the dataset is in CSR format with 1st 3 entries as [user_id, col_id, ratings, ... ] and ratings are in between 1 - 5. Else, you will have to make changes to original jupyter notebook) and get performance evaluation of THE algorithm. <br>\n",
    "There also maybe some substitute functions for your use other than those mentioned in this testscript. Look into the original jupyter notebook for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the main Jupyter notebook which has all the functions defined. Make sure the path is correct in next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.time(18, 36, 26, 857077)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().time()     # (hour, min, sec, microsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if this way of importing another jupyter notebook fails for you\n",
    "# then you can use any one of the many methods described here:\n",
    "# https://stackoverflow.com/questions/20186344/ipynb-import-another-ipynb-file\n",
    "%run 'finalcode.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.time(18, 36, 28, 884102)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().time()     # (hour, min, sec, microsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Dataset Parameters'''\n",
    "################################################################################################################\n",
    "DATA_PATH = './ml-100k/u.data' # ml-100k data set has 100k ratings, 943 users and 1682 items\n",
    "DELIMITER = \"\\t\"               # tab separated or comma separated data format\n",
    "N_RATINGS = 100000\n",
    "################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These parameters will be detected automatically from dataset\n",
    "# -1 is for the default value\n",
    "FIRST_INDEX = -1\n",
    "USERS = -1\n",
    "ITEMS = -1\n",
    "SPARSITY = -1                  # 'p' in the equations\n",
    "UNOBSERVED = 0                 # default value in matrix for unobserved ratings; prefer to keep it 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To reduce size of csr for testing purpose\n",
    "# WARNING: ONLY TO BE USED FOR TESTING\n",
    "# (for real run, put SIZE_REDUCTION = False)\n",
    "SIZE_REDUCTION = True\n",
    "USER_LIMIT = 20\n",
    "ITEM_LIMIT = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Hyperparameters'''\n",
    "# All the hyperparameters have default values\n",
    "#To use them, set the parameters as -1\n",
    "################################################################################################################\n",
    "TRAIN_TEST_SPLIT = -1                   # %age of test ratings wrt train rating ; value in between 0 and 1\n",
    "C1 = -1                                 # probability of edges in training set going to E1\n",
    "C2 = -1                                 # probability of edges in training set going to E2\n",
    "RADIUS = 1                              # radius of neighborhood, radius = # edges between start and end vertex\n",
    "UNPRED_RATING = 3                       # rating (normalized) for which we dont have predicted rating between 1 - 5\n",
    "THRESHOLD = 0.01                        # distance similarity threshold used for rating prediction\n",
    "################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 = 0.33 (default)\n",
      "c2 = 0.33 (default)\n",
      "c3 = 0.34 (default)\n",
      "Radius = 1\n",
      "Rating set for unpredicted ratings = 3\n",
      "TRAIN_TEST_SPLIT = 0.2 (default)\n"
     ]
    }
   ],
   "source": [
    "# checks on hyper parameters    \n",
    "if isinstance(C1, float) and isinstance(C2, float) and (C1 > 0) and (C2 > 0) and 1 - C1 - C2 > 0:\n",
    "    print('c1 = {}'.format(C1))\n",
    "    print('c2 = {}'.format(C2))\n",
    "    print('c3 = {}'.format(1-C1-C2))\n",
    "elif (C1 == -1) and (C2 == -1):\n",
    "    C1 = C2 = 0.33\n",
    "    print('c1 = {} (default)'.format(C1))\n",
    "    print('c2 = {} (default)'.format(C2))\n",
    "    print('c3 = {} (default)'.format(1-C1-C2))\n",
    "else:\n",
    "    print('ERROR: Incorrect values set for C1 and C2')\n",
    "    \n",
    "if isinstance(RADIUS, int) and RADIUS > 0:\n",
    "    print('Radius = {}'.format(RADIUS))\n",
    "elif RADIUS == -1:\n",
    "    print('Radius = default value as per paper')\n",
    "else:\n",
    "    print('ERROR: Incorrect values set for Radius')\n",
    "\n",
    "if UNPRED_RATING >= 1 and UNPRED_RATING <= 5:\n",
    "    print('Rating set for unpredicted ratings = {}'. format(UNPRED_RATING))\n",
    "elif UNPRED_RATING == -1:\n",
    "    UNPRED_RATING = 3\n",
    "    print('Rating set for unpredicted ratings = {} (default)'. format(UNPRED_RATING))\n",
    "else:\n",
    "    print('ERROR: Incorrect values set for UNPRED_RATING')\n",
    "    \n",
    "if TRAIN_TEST_SPLIT > 0 and TRAIN_TEST_SPLIT < 1:\n",
    "    print('TRAIN_TEST_SPLIT = {}'.format(TRAIN_TEST_SPLIT))\n",
    "elif TRAIN_TEST_SPLIT == -1:\n",
    "    TRAIN_TEST_SPLIT = 0.2\n",
    "    print('TRAIN_TEST_SPLIT = 0.2 (default)')\n",
    "else:\n",
    "    print('ERROR: Incorrect values set for TRAIN_TEST_SPLIT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: FOR TESTING PURPOSES ONLY\n",
      "Reading dataset: done\n",
      "USERS = 20\n",
      "ITEMS = 50\n",
      "All users and items have at least one rating! Good!\n",
      "SPARSITY (p) = 0.100816326531\n",
      "Sym matrix : p is polynomially larger than 1/n, all guarantees applicable\n",
      "Check and set dataset : done\n"
     ]
    }
   ],
   "source": [
    "data_csr = read_data_csr(fname=DATA_PATH, delimiter=DELIMITER)\n",
    "\n",
    "if SIZE_REDUCTION:\n",
    "    data_csr = reduce_size_of_data_csr(data_csr)\n",
    "\n",
    "if data_csr.shape[0] == N_RATINGS:  # gives total no of ratings read; useful for verification\n",
    "    print('Reading dataset: done')\n",
    "else:\n",
    "    print('Reading dataset: FAILED')\n",
    "    print( '# of missing ratings: ' + str(N_RATINGS - data_csr.shape[0]))\n",
    "    \n",
    "check_and_set_data_csr(data_csr=data_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating train test split: done\n"
     ]
    }
   ],
   "source": [
    "[train_data_csr, test_data_csr] = generate_train_test_split_csr(data_csr=data_csr, split=TRAIN_TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize ratings: done\n",
      "CSR to symmetric CSR matrix: done\n"
     ]
    }
   ],
   "source": [
    "train_data_csr = normalize_ratings_csr(train_data_csr)\n",
    "train_data_csr = csr_to_symmetric_csr(train_data_csr)\n",
    "# the symmetric matrix obtained doesnt contain repititions for any user item pair\n",
    "# only the item_ids are scaled by item_ids += USERS\n",
    "# hence, we can safely go ahead and use this CSR matrix for sample splitting step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions using THE algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Sample splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample splitting: done\n"
     ]
    }
   ],
   "source": [
    "[m1_csr, m2_csr, m3_csr] = sample_splitting_csr(data_csr=train_data_csr, c1=C1, c2=C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Expanding the Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graph as dictionary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 10310.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating neighbor boundary matrix at 1-hop distance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 21812.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating neighbor boundary matrix at 2-hop distance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 8715.05it/s]\n"
     ]
    }
   ],
   "source": [
    "[r_neighbor_matrix, r1_neighbor_matrix] = generate_neighbor_boundary_matrix(m1_csr)\n",
    "# all neighbor boundary vector for each user u is stored as u'th row in neighbor_matrix\n",
    "# though here the vector is stored a row vector, we will treat it as column vector in Step 4\n",
    "# Note: we might expect neighbor matrix to be symmetric with dimensions (USERS+ITEMS)*(USERS+ITEMS)\n",
    "#     : since distance user-item and item-user should be same\n",
    "#     : but this is not the case since there might be multiple paths between user-item\n",
    "#     : and the random path picked for user-item and item-user may not be same\n",
    "#     : normalizing the matrix also will result to rise of difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To effectively choose RADIUS value for next run of algorithm:\n",
      "Showing distribution of count of neighbors for every vertex:\n",
      "               0\n",
      "count  70.000000\n",
      "mean    1.857143\n",
      "std     2.515377\n",
      "min     0.000000\n",
      "25%     0.000000\n",
      "50%     1.000000\n",
      "75%     3.000000\n",
      "max    17.000000\n"
     ]
    }
   ],
   "source": [
    "describe_neighbor_count(r_neighbor_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To effectively choose RADIUS value for next run of algorithm:\n",
      "Showing distribution of count of neighbors for every vertex:\n",
      "               0\n",
      "count  70.000000\n",
      "mean    7.057143\n",
      "std     7.436467\n",
      "min     0.000000\n",
      "25%     0.000000\n",
      "50%     4.500000\n",
      "75%    15.500000\n",
      "max    23.000000\n"
     ]
    }
   ],
   "source": [
    "describe_neighbor_count(r1_neighbor_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Computing the distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating distance matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 437.20it/s]\n"
     ]
    }
   ],
   "source": [
    "distance_matrix = compute_distance_matrix(r_neighbor_matrix, r1_neighbor_matrix, m2_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To effectively choose THRESHOLD value in next step:\n",
      "Showing distribution of non zero (or observed) entries of distance matrix:\n",
      "                 0\n",
      "count  2912.000000\n",
      "mean      0.653221\n",
      "std       1.806185\n",
      "min     -13.947678\n",
      "25%       0.056246\n",
      "50%       0.637608\n",
      "75%       1.743460\n",
      "max       5.335632\n"
     ]
    }
   ],
   "source": [
    "describe_distance_matrix(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4: Averaging datapoints to produce final estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prefer to choose a threshold now based on describe_distance_matrix\n",
    "THRESHOLD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating distance similarity matrix:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 4119.85it/s]\n"
     ]
    }
   ],
   "source": [
    "sim_matrix = generate_sim_matrix(distance_matrix, threshold=THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize ratings: done\n",
      "CSR to symmetric CSR matrix: done\n"
     ]
    }
   ],
   "source": [
    "# Prepare the test dataset using Model preparation section functions\n",
    "test_data_csr = normalize_ratings_csr(test_data_csr)\n",
    "test_data_csr = csr_to_symmetric_csr(test_data_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction array:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 174.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Getting estimates for only test data points\n",
    "prediction_array = generate_averaged_prediction_array(sim_matrix, m3_csr, test_data_csr)\n",
    "\n",
    "# To generate complete rating matrix do the following:\n",
    "#prediction_matrix = generate_averaged_prediction_matrix(sim_matrix, m3_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have already prepared the test data (required for our algorithm)\n",
    "y_actual  = test_data_csr[:,2]\n",
    "y_predict = prediction_array\n",
    "# If we want, we could scale our ratings back to 1 - 5 range for evaluation purposes\n",
    "#But then paper makes no guarantees about scaled ratings\n",
    "#y_actual  = y_actual * 5\n",
    "#y_predict = y_predict * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23394521972792753"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(y_actual, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18892558458568748"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_err(y_actual, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Upper bound: 0.67650999627\n",
      "MSE of predictions: 0.0547303658335\n",
      "As per the discussion in the paper, MSE is bounded by O((pn)**(-1/5))\n"
     ]
    }
   ],
   "source": [
    "check_mse(m1_csr, y_actual, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.time(18, 36, 31, 815093)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().time()     # (hour, min, sec, microsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
