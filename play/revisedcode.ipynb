{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing important modules which will be used in this jupyter notebook throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Built and testing on python2\n",
    "import numpy as np\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Notations\n",
    "$u$ = user <br>\n",
    "$i$ = item <br>\n",
    "$M$ = symmetric rating matrix of size $n \\times n$ (usually the dataset) <br>\n",
    "$E$ = set of $(u,i)$ if, user $u$ has rated item $i$ in matrix $M$ (intuitively $E$ is edge matrix between user and items. <br>\n",
    "$p$ = sparsity of $M$ i.e. (= #observed ratings in $M$ / total # ratings in $M$)<br>\n",
    "$r$ = radius, distance (in no of edges) between user $u$ and item $i$ at neighborhood boundary (look in step 2) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparation\n",
    "We first look at function which converts our asymmetric rating matrix to a symmetric matix and another function that normalizes the ratings between [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Details\n",
    "As per paper: *We present and discuss details of each step of the algorithm, which primarily involves computing pairwise distances (or similarities) between vertices.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Sample Splitting\n",
    "Partition the rating matrix into three different parts. Following are the exerpts from paper:\n",
    "- *Each edge in $E$ is independently placed into $E_1, E_2,$ or $E_3$, with probabilities $c_1, c_2,$ and $1 - c_1 - c_2$ respectively. Matrices $M_1, M_2$, and $M_3$ contain information from the subset of the data in $M$ associated to $E_1, E_2$, and $E_3$ respectively.*\n",
    "- *$M_1$ is used to define local neighborhoods of each vertex (in step 2), $M_2$ is used to compute similarities of these neighborhoods (in step 3), and $M_3$ is used to average over datapoints for the final estimate (in step 4)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Expanding the Neighborhood\n",
    "We do the following in this step:\n",
    "- radius $r$ to be tuned using cross validation. We can use its default value as $r = \\frac{6\\ln(1/p)}{8\\ln(c_1pn)}$ as per paper.\n",
    "- use matrix $M_1$ to build neighborhood based on radius $r$\n",
    "- Build BFS tree rooted at each vertex to get product of the path from user to item, such that\n",
    "  - each vertex (user or item) in a path from user to boundary item is unique\n",
    "  - the path chosen is the shortest path (#path edges) between the user and the boundary item\n",
    "  - in case of multiple paths (or trees), choose any one path (i.e. any one tree) at random\n",
    "- Normalize the product of ratings by total no of final items at the boundary\n",
    "\n",
    "$N_{u,r}$ obtained is a vector for user $u$ for $r$-hop, where each element is product of path from user to item or zero. $\\tilde{N_{u,r}}$ is normalized vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Computing the distances\n",
    "Distance computation between two users (using matrix $M_2$) using the following formula (only $dist_1$ implemented for now):\n",
    "\n",
    "$$ dist(u,v) = \\left(\\frac{1 - c_1p}{c_2p}\\right) (\\tilde{N_{u,r}} - \\tilde{N_{v,r}})^T M_2 (\\tilde{N_{u,r+1}} - \\tilde{N_{v,r+1}}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Averaging datapoints to produce final estimate\n",
    "Average over nearby data points based on the distance(similarity) threshold $n_n$ (using matrix $M_3$). $n_n$ to be tuned using cross validation. Mathematically (from paper):\n",
    "\n",
    "$$ \\hat{F_{u,v}} = \\frac{1}{\\mid E_{uv1} \\mid} \\sum_{(a,b) \\in E_{uv1}} M_3(a,b) $$\n",
    "*where $E_{uv1}$ denotes the set of undirected edges $(a, b)$ such that $(a, b) \\in E_3$ and both $dist(u, a)$ and $dist_1(v, b)$ are less than $n_n$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other important functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Handling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substitute functions\n",
    "Functions which can also be used instead of algorithm specific implementations for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "We evaluate our recommendation algorithm using RMSE (root mean square error). <br>\n",
    "According to paper, if sparsity $p$ is polynomially larger than $n^{-1}$, i.e. if $p = n^{-1 + \\epsilon}$ for $\\epsilon > 0$, then we can safely use $dist_1$ distance computation formula and MSE is bounded by $O((pn)^{-1/5})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Script / Experiment\n",
    "The following jupyter notebook cells make calls to above cells to run experiments on a recommendation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
